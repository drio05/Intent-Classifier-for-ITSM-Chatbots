{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe4087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071cad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wget\n",
    "# url = 'https://raw.githubusercontent.com/clinc/oos-eval/master/data/data_full.json'\n",
    "# wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02a4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "# Loading json data\n",
    "with open('data_full.json') as file:\n",
    "  data = json.loads(file.read())\n",
    "\n",
    "# Loading out-of-scope intent data\n",
    "val_oos = np.array(data['oos_val'])\n",
    "train_oos = np.array(data['oos_train'])\n",
    "test_oos = np.array(data['oos_test'])\n",
    "\n",
    "# Loading other intents data\n",
    "val_others = np.array(data['val'])\n",
    "train_others = np.array(data['train'])\n",
    "test_others = np.array(data['test'])\n",
    "\n",
    "# Merging out-of-scope and other intent data\n",
    "val = np.concatenate([val_oos,val_others])\n",
    "train = np.concatenate([train_oos,train_others])\n",
    "test = np.concatenate([test_oos,test_others])\n",
    "data = np.concatenate([train,test,val])\n",
    "data = data.T\n",
    "\n",
    "text = data[0]\n",
    "labels = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4add7a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['how much is an overdraft fee for bank',\n",
       "        'why are exponents preformed before multiplication in the order of operations',\n",
       "        'what size wipers does this car take', ...,\n",
       "        \"do you know why my card was declined at target i can't figure out why\",\n",
       "        \"i can't figure out why my card was declined at target\",\n",
       "        \"i was just at target and they declined my card and i can't understand why\"],\n",
       "       ['oos', 'oos', 'oos', ..., 'card_declined', 'card_declined',\n",
       "        'card_declined']], dtype='<U136')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0613662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_txt,test_txt,train_label,test_labels = train_test_split(text,labels,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d01c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "max_num_words = 40000\n",
    "classes = np.unique(labels)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts(train_txt)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575ef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "for c in train_txt:\n",
    "    ls.append(len(c.split()))\n",
    "maxLen=int(np.percentile(ls, 98))\n",
    "train_sequences = tokenizer.texts_to_sequences(train_txt)\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=maxLen,              padding='post')\n",
    "test_sequences = tokenizer.texts_to_sequences(test_txt)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a49e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(classes)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoder.fit(integer_encoded)\n",
    "train_label_encoded = label_encoder.transform(train_label)\n",
    "train_label_encoded = train_label_encoded.reshape(len(train_label_encoded), 1)\n",
    "train_label = onehot_encoder.transform(train_label_encoded)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "test_labels_encoded = test_labels_encoded.reshape(len(test_labels_encoded), 1)\n",
    "test_labels = onehot_encoder.transform(test_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1bffe60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import wget\n",
    "# url ='https://www.dropbox.com/s/a247ju2qsczh0be/glove.6B.100d.txt?dl=1'\n",
    "# wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f19a5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index={}\n",
    "with open('glove.6B.100d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7054df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3309: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "num_words = min(max_num_words, len(word_index))+1\n",
    "embedding_dim=len(embeddings_index['the'])\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_num_words:\n",
    "        break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c411b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional,Embedding\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 100, trainable=False,input_length=train_sequences.shape[1], weights=[embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.1, dropout=0.1), 'concat'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=False, recurrent_dropout=0.1, dropout=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(classes.shape[0], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a05fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "with tf.device('/device:GPU:0'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e5075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "260/260 [==============================] - ETA: 0s - loss: 4.7311 - acc: 0.0502WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 16) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 151) dtype=float32>)\n",
      "Consider rewriting this model with the Functional API.\n",
      "260/260 [==============================] - 161s 586ms/step - loss: 4.7311 - acc: 0.0502 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 155s 598ms/step - loss: 3.2886 - acc: 0.1844 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "166/260 [==================>...........] - ETA: 52s - loss: 2.3040 - acc: 0.3754"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences, train_label, epochs = 5,\n",
    "          batch_size = 64, shuffle=True,\n",
    "          validation_data=[test_sequences, test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f270cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6cb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537322c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
